Search.setIndex({"alltitles": {"API Documentation": [[1, null]], "Attention Modules": [[1, "attention-modules"]], "Contents:": [[0, null]], "Features": [[0, "features"]], "Functional Interfaces": [[1, "functional-interfaces"]], "Indices and tables": [[0, "indices-and-tables"]], "Installation": [[0, "installation"]], "Models": [[1, "module-jaxgarden.models"]], "Welcome to JAXgarden documentation!": [[0, null]]}, "docnames": ["index", "modules/index"], "envversion": {"sphinx": 64, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.viewcode": 1}, "filenames": ["index.rst", "modules/index.rst"], "indexentries": {"__call__() (jaxgarden.models.gemma2rotaryembedding method)": [[1, "jaxgarden.models.Gemma2RotaryEmbedding.__call__", false]], "__call__() (jaxgarden.models.gemma3rotaryembedding method)": [[1, "jaxgarden.models.Gemma3RotaryEmbedding.__call__", false]], "__call__() (jaxgarden.models.llamaattention method)": [[1, "jaxgarden.models.LlamaAttention.__call__", false]], "__call__() (jaxgarden.models.llamaforcausallm method)": [[1, "jaxgarden.models.LlamaForCausalLM.__call__", false]], "__call__() (jaxgarden.models.llamamlp method)": [[1, "jaxgarden.models.LlamaMLP.__call__", false]], "__call__() (jaxgarden.models.llamarmsnorm method)": [[1, "jaxgarden.models.LlamaRMSNorm.__call__", false]], "__call__() (jaxgarden.models.llamarotaryembedding method)": [[1, "jaxgarden.models.LlamaRotaryEmbedding.__call__", false]], "__call__() (jaxgarden.models.llamatransformerblock method)": [[1, "jaxgarden.models.LlamaTransformerBlock.__call__", false]], "__call__() (jaxgarden.models.modernbertattention method)": [[1, "jaxgarden.models.ModernBertAttention.__call__", false]], "__call__() (jaxgarden.models.modernbertembeddings method)": [[1, "jaxgarden.models.ModernBertEmbeddings.__call__", false]], "__call__() (jaxgarden.models.modernbertencoder method)": [[1, "jaxgarden.models.ModernBERTEncoder.__call__", false]], "__call__() (jaxgarden.models.modernbertformaskedlm method)": [[1, "jaxgarden.models.ModernBERTForMaskedLM.__call__", false]], "__call__() (jaxgarden.models.modernbertlayer method)": [[1, "jaxgarden.models.ModernBertLayer.__call__", false]], "__call__() (jaxgarden.models.modernbertmlp method)": [[1, "jaxgarden.models.ModernBertMLP.__call__", false]], "__init__() (jaxgarden.attention.multiheadattention method)": [[1, "jaxgarden.attention.MultiHeadAttention.__init__", false]], "__init__() (jaxgarden.models.basemodel method)": [[1, "jaxgarden.models.BaseModel.__init__", false]], "__init__() (jaxgarden.models.llamaattention method)": [[1, "jaxgarden.models.LlamaAttention.__init__", false]], "__init__() (jaxgarden.models.llamaforcausallm method)": [[1, "jaxgarden.models.LlamaForCausalLM.__init__", false]], "__init__() (jaxgarden.models.llamamlp method)": [[1, "jaxgarden.models.LlamaMLP.__init__", false]], "__init__() (jaxgarden.models.llamarmsnorm method)": [[1, "jaxgarden.models.LlamaRMSNorm.__init__", false]], "__init__() (jaxgarden.models.llamarotaryembedding method)": [[1, "jaxgarden.models.LlamaRotaryEmbedding.__init__", false]], "__init__() (jaxgarden.models.llamatransformerblock method)": [[1, "jaxgarden.models.LlamaTransformerBlock.__init__", false]], "__init__() (jaxgarden.models.modernbertattention method)": [[1, "jaxgarden.models.ModernBertAttention.__init__", false]], "__init__() (jaxgarden.models.modernbertembeddings method)": [[1, "jaxgarden.models.ModernBertEmbeddings.__init__", false]], "__init__() (jaxgarden.models.modernbertencoder method)": [[1, "jaxgarden.models.ModernBERTEncoder.__init__", false]], "__init__() (jaxgarden.models.modernbertformaskedlm method)": [[1, "jaxgarden.models.ModernBERTForMaskedLM.__init__", false]], "__init__() (jaxgarden.models.modernbertlayer method)": [[1, "jaxgarden.models.ModernBertLayer.__init__", false]], "__init__() (jaxgarden.models.modernbertmlp method)": [[1, "jaxgarden.models.ModernBertMLP.__init__", false]], "apply_rotary_pos_emb() (jaxgarden.models.llamaattention method)": [[1, "jaxgarden.models.LlamaAttention.apply_rotary_pos_emb", false]], "apply_soft_cap() (jaxgarden.models.gemma2attention static method)": [[1, "jaxgarden.models.Gemma2Attention.apply_soft_cap", false]], "apply_soft_cap() (jaxgarden.models.gemma3attention static method)": [[1, "jaxgarden.models.Gemma3Attention.apply_soft_cap", false]], "attention (jaxgarden.models.llamatransformerblock attribute)": [[1, "jaxgarden.models.LlamaTransformerBlock.attention", false]], "attention_bias (jaxgarden.models.gemma3config attribute)": [[1, "id0", false], [1, "jaxgarden.models.Gemma3Config.attention_bias", false]], "attention_dropout (jaxgarden.models.gemma3config attribute)": [[1, "id9", false], [1, "jaxgarden.models.Gemma3Config.attention_dropout", false]], "attn_logit_soft_cap (jaxgarden.models.gemma3config attribute)": [[1, "id10", false], [1, "jaxgarden.models.Gemma3Config.attn_logit_soft_cap", false]], "attn_logits_soft_cap (jaxgarden.models.gemma2config attribute)": [[1, "jaxgarden.models.Gemma2Config.attn_logits_soft_cap", false]], "base (jaxgarden.models.llamarotaryembedding attribute)": [[1, "jaxgarden.models.LlamaRotaryEmbedding.base", false]], "baseconfig (class in jaxgarden.models)": [[1, "jaxgarden.models.BaseConfig", false]], "basemodel (class in jaxgarden.models)": [[1, "jaxgarden.models.BaseModel", false]], "bos_token_id (jaxgarden.models.gemma3config attribute)": [[1, "id11", false], [1, "jaxgarden.models.Gemma3Config.bos_token_id", false]], "config (jaxgarden.models.gemma2forcausallm attribute)": [[1, "jaxgarden.models.Gemma2ForCausalLM.config", false]], "config (jaxgarden.models.gemma3forcausallm attribute)": [[1, "jaxgarden.models.Gemma3ForCausalLM.config", false]], "context_length (jaxgarden.models.gemma2config attribute)": [[1, "jaxgarden.models.Gemma2Config.context_length", false]], "convert_weights_from_hf() (jaxgarden.models.basemodel method)": [[1, "jaxgarden.models.BaseModel.convert_weights_from_hf", false]], "convert_weights_from_hf() (jaxgarden.models.llamaforcausallm method)": [[1, "jaxgarden.models.LlamaForCausalLM.convert_weights_from_hf", false]], "dim (jaxgarden.models.llamaconfig attribute)": [[1, "id34", false], [1, "jaxgarden.models.LlamaConfig.dim", false]], "dim (jaxgarden.models.llamarotaryembedding attribute)": [[1, "jaxgarden.models.LlamaRotaryEmbedding.dim", false]], "dot_product_attention() (in module jaxgarden.functional)": [[1, "jaxgarden.functional.dot_product_attention", false]], "down_proj (jaxgarden.models.llamamlp attribute)": [[1, "jaxgarden.models.LlamaMLP.down_proj", false]], "download_from_hf() (jaxgarden.models.basemodel static method)": [[1, "jaxgarden.models.BaseModel.download_from_hf", false]], "dtype (jaxgarden.models.gemma2config attribute)": [[1, "jaxgarden.models.Gemma2Config.dtype", false]], "dtype (jaxgarden.models.gemma3config attribute)": [[1, "jaxgarden.models.Gemma3Config.dtype", false]], "eos_token_id (jaxgarden.models.gemma2config attribute)": [[1, "jaxgarden.models.Gemma2Config.eos_token_id", false]], "eos_token_id (jaxgarden.models.gemma3config attribute)": [[1, "id12", false], [1, "jaxgarden.models.Gemma3Config.eos_token_id", false]], "extra (jaxgarden.models.baseconfig attribute)": [[1, "jaxgarden.models.BaseConfig.extra", false]], "final_logit_soft_cap (jaxgarden.models.gemma2config attribute)": [[1, "jaxgarden.models.Gemma2Config.final_logit_soft_cap", false]], "final_logit_soft_cap (jaxgarden.models.gemma3config attribute)": [[1, "id13", false], [1, "jaxgarden.models.Gemma3Config.final_logit_soft_cap", false]], "from_hf() (jaxgarden.models.basemodel method)": [[1, "jaxgarden.models.BaseModel.from_hf", false]], "gate_proj (jaxgarden.models.llamamlp attribute)": [[1, "jaxgarden.models.LlamaMLP.gate_proj", false]], "geglu() (jaxgarden.models.gemma2mlp static method)": [[1, "jaxgarden.models.Gemma2MLP.geglu", false]], "gemma2attention (class in jaxgarden.models)": [[1, "jaxgarden.models.Gemma2Attention", false]], "gemma2config (class in jaxgarden.models)": [[1, "jaxgarden.models.Gemma2Config", false]], "gemma2forcausallm (class in jaxgarden.models)": [[1, "jaxgarden.models.Gemma2ForCausalLM", false]], "gemma2mlp (class in jaxgarden.models)": [[1, "jaxgarden.models.Gemma2MLP", false]], "gemma2rmsnorm (class in jaxgarden.models)": [[1, "jaxgarden.models.Gemma2RMSNorm", false]], "gemma2rotaryembedding (class in jaxgarden.models)": [[1, "jaxgarden.models.Gemma2RotaryEmbedding", false]], "gemma3attention (class in jaxgarden.models)": [[1, "jaxgarden.models.Gemma3Attention", false]], "gemma3config (class in jaxgarden.models)": [[1, "jaxgarden.models.Gemma3Config", false]], "gemma3forcausallm (class in jaxgarden.models)": [[1, "jaxgarden.models.Gemma3ForCausalLM", false]], "gemma3mlp (class in jaxgarden.models)": [[1, "jaxgarden.models.Gemma3MLP", false]], "gemma3rmsnorm (class in jaxgarden.models)": [[1, "jaxgarden.models.Gemma3RMSNorm", false]], "gemma3rotaryembedding (class in jaxgarden.models)": [[1, "jaxgarden.models.Gemma3RotaryEmbedding", false]], "generate() (jaxgarden.models.generationmixin method)": [[1, "jaxgarden.models.GenerationMixin.generate", false]], "generationmixin (class in jaxgarden.models)": [[1, "jaxgarden.models.GenerationMixin", false]], "head_dim (jaxgarden.models.gemma2config attribute)": [[1, "jaxgarden.models.Gemma2Config.head_dim", false]], "head_dim (jaxgarden.models.gemma3config attribute)": [[1, "id14", false], [1, "jaxgarden.models.Gemma3Config.head_dim", false]], "head_dim (jaxgarden.models.llamaattention attribute)": [[1, "jaxgarden.models.LlamaAttention.head_dim", false]], "head_dim (jaxgarden.models.llamaconfig attribute)": [[1, "id35", false], [1, "jaxgarden.models.LlamaConfig.head_dim", false]], "hidden_activation (jaxgarden.models.gemma3config attribute)": [[1, "id15", false], [1, "jaxgarden.models.Gemma3Config.hidden_activation", false]], "hidden_size (jaxgarden.models.gemma2config attribute)": [[1, "jaxgarden.models.Gemma2Config.hidden_size", false]], "hidden_size (jaxgarden.models.gemma3config attribute)": [[1, "id16", false], [1, "jaxgarden.models.Gemma3Config.hidden_size", false]], "initializer_range (jaxgarden.models.gemma3config attribute)": [[1, "id17", false], [1, "jaxgarden.models.Gemma3Config.initializer_range", false]], "input_layernorm (jaxgarden.models.llamatransformerblock attribute)": [[1, "jaxgarden.models.LlamaTransformerBlock.input_layernorm", false]], "intermediate_size (jaxgarden.models.gemma2config attribute)": [[1, "jaxgarden.models.Gemma2Config.intermediate_size", false]], "intermediate_size (jaxgarden.models.gemma3config attribute)": [[1, "id18", false], [1, "jaxgarden.models.Gemma3Config.intermediate_size", false]], "intermediate_size (jaxgarden.models.llamaconfig attribute)": [[1, "id36", false], [1, "jaxgarden.models.LlamaConfig.intermediate_size", false]], "iter_safetensors() (jaxgarden.models.basemodel static method)": [[1, "jaxgarden.models.BaseModel.iter_safetensors", false]], "jaxgarden.attention": [[1, "module-jaxgarden.attention", false]], "jaxgarden.functional": [[1, "module-jaxgarden.functional", false]], "jaxgarden.models": [[1, "module-jaxgarden.models", false]], "k_proj (jaxgarden.models.llamaattention attribute)": [[1, "jaxgarden.models.LlamaAttention.k_proj", false]], "layers (jaxgarden.models.llamaforcausallm attribute)": [[1, "jaxgarden.models.LlamaForCausalLM.layers", false]], "llamaattention (class in jaxgarden.models)": [[1, "jaxgarden.models.LlamaAttention", false]], "llamaconfig (class in jaxgarden.models)": [[1, "jaxgarden.models.LlamaConfig", false]], "llamaforcausallm (class in jaxgarden.models)": [[1, "jaxgarden.models.LlamaForCausalLM", false]], "llamamlp (class in jaxgarden.models)": [[1, "jaxgarden.models.LlamaMLP", false]], "llamarmsnorm (class in jaxgarden.models)": [[1, "jaxgarden.models.LlamaRMSNorm", false]], "llamarotaryembedding (class in jaxgarden.models)": [[1, "jaxgarden.models.LlamaRotaryEmbedding", false]], "llamatransformerblock (class in jaxgarden.models)": [[1, "jaxgarden.models.LlamaTransformerBlock", false]], "lm_head (jaxgarden.models.llamaforcausallm attribute)": [[1, "jaxgarden.models.LlamaForCausalLM.lm_head", false]], "load() (jaxgarden.models.basemodel method)": [[1, "jaxgarden.models.BaseModel.load", false]], "log_level (jaxgarden.models.baseconfig attribute)": [[1, "jaxgarden.models.BaseConfig.log_level", false]], "max_position_embeddings (jaxgarden.models.gemma3config attribute)": [[1, "id19", false], [1, "jaxgarden.models.Gemma3Config.max_position_embeddings", false]], "mlp (jaxgarden.models.llamatransformerblock attribute)": [[1, "jaxgarden.models.LlamaTransformerBlock.mlp", false]], "modernbertattention (class in jaxgarden.models)": [[1, "jaxgarden.models.ModernBertAttention", false]], "modernbertembeddings (class in jaxgarden.models)": [[1, "jaxgarden.models.ModernBertEmbeddings", false]], "modernbertencoder (class in jaxgarden.models)": [[1, "jaxgarden.models.ModernBERTEncoder", false]], "modernbertformaskedlm (class in jaxgarden.models)": [[1, "jaxgarden.models.ModernBERTForMaskedLM", false]], "modernbertlayer (class in jaxgarden.models)": [[1, "jaxgarden.models.ModernBertLayer", false]], "modernbertmlp (class in jaxgarden.models)": [[1, "jaxgarden.models.ModernBertMLP", false]], "module": [[1, "module-jaxgarden.attention", false], [1, "module-jaxgarden.functional", false], [1, "module-jaxgarden.models", false]], "multiheadattention (class in jaxgarden.attention)": [[1, "jaxgarden.attention.MultiHeadAttention", false]], "multiple_of (jaxgarden.models.llamaconfig attribute)": [[1, "id37", false], [1, "jaxgarden.models.LlamaConfig.multiple_of", false]], "n_heads (jaxgarden.models.llamaattention attribute)": [[1, "jaxgarden.models.LlamaAttention.n_heads", false]], "n_heads (jaxgarden.models.llamaconfig attribute)": [[1, "id38", false], [1, "jaxgarden.models.LlamaConfig.n_heads", false]], "n_kv_heads (jaxgarden.models.llamaattention attribute)": [[1, "jaxgarden.models.LlamaAttention.n_kv_heads", false]], "n_kv_heads (jaxgarden.models.llamaconfig attribute)": [[1, "id39", false], [1, "jaxgarden.models.LlamaConfig.n_kv_heads", false]], "n_layers (jaxgarden.models.llamaconfig attribute)": [[1, "id40", false], [1, "jaxgarden.models.LlamaConfig.n_layers", false]], "norm (jaxgarden.models.llamaforcausallm attribute)": [[1, "jaxgarden.models.LlamaForCausalLM.norm", false]], "norm_eps (jaxgarden.models.llamaconfig attribute)": [[1, "id41", false], [1, "jaxgarden.models.LlamaConfig.norm_eps", false]], "norm_eps (jaxgarden.models.llamarmsnorm attribute)": [[1, "jaxgarden.models.LlamaRMSNorm.norm_eps", false]], "norm_weights (jaxgarden.models.llamarmsnorm attribute)": [[1, "jaxgarden.models.LlamaRMSNorm.norm_weights", false]], "num_attention_heads (jaxgarden.models.gemma2config attribute)": [[1, "jaxgarden.models.Gemma2Config.num_attention_heads", false]], "num_attention_heads (jaxgarden.models.gemma3config attribute)": [[1, "id20", false], [1, "jaxgarden.models.Gemma3Config.num_attention_heads", false]], "num_hidden_layers (jaxgarden.models.gemma2config attribute)": [[1, "jaxgarden.models.Gemma2Config.num_hidden_layers", false]], "num_hidden_layers (jaxgarden.models.gemma3config attribute)": [[1, "id21", false], [1, "jaxgarden.models.Gemma3Config.num_hidden_layers", false]], "num_key_value_heads (jaxgarden.models.gemma2config attribute)": [[1, "jaxgarden.models.Gemma2Config.num_key_value_heads", false]], "num_key_value_heads (jaxgarden.models.gemma3config attribute)": [[1, "id22", false], [1, "jaxgarden.models.Gemma3Config.num_key_value_heads", false]], "o_proj (jaxgarden.models.llamaattention attribute)": [[1, "jaxgarden.models.LlamaAttention.o_proj", false]], "pad_token_id (jaxgarden.models.gemma2config attribute)": [[1, "jaxgarden.models.Gemma2Config.pad_token_id", false]], "pad_token_id (jaxgarden.models.gemma3config attribute)": [[1, "id23", false], [1, "jaxgarden.models.Gemma3Config.pad_token_id", false]], "param_dtype (jaxgarden.models.gemma2config attribute)": [[1, "jaxgarden.models.Gemma2Config.param_dtype", false]], "param_dtype (jaxgarden.models.gemma3config attribute)": [[1, "jaxgarden.models.Gemma3Config.param_dtype", false]], "post_attention_layernorm (jaxgarden.models.llamatransformerblock attribute)": [[1, "jaxgarden.models.LlamaTransformerBlock.post_attention_layernorm", false]], "q_proj (jaxgarden.models.llamaattention attribute)": [[1, "jaxgarden.models.LlamaAttention.q_proj", false]], "query_pre_attn_scalar (jaxgarden.models.gemma3config attribute)": [[1, "id24", false], [1, "jaxgarden.models.Gemma3Config.query_pre_attn_scalar", false]], "repeat_kv() (jaxgarden.models.llamaattention static method)": [[1, "jaxgarden.models.LlamaAttention.repeat_kv", false]], "rms_norm_eps (jaxgarden.models.gemma2config attribute)": [[1, "jaxgarden.models.Gemma2Config.rms_norm_eps", false]], "rms_norm_eps (jaxgarden.models.gemma3config attribute)": [[1, "id25", false], [1, "jaxgarden.models.Gemma3Config.rms_norm_eps", false]], "rope_local_base_freq (jaxgarden.models.gemma3config attribute)": [[1, "id26", false], [1, "jaxgarden.models.Gemma3Config.rope_local_base_freq", false]], "rope_scaling (jaxgarden.models.gemma3config attribute)": [[1, "id27", false], [1, "jaxgarden.models.Gemma3Config.rope_scaling", false]], "rope_theta (jaxgarden.models.gemma2config attribute)": [[1, "jaxgarden.models.Gemma2Config.rope_theta", false]], "rope_theta (jaxgarden.models.gemma3config attribute)": [[1, "id28", false], [1, "jaxgarden.models.Gemma3Config.rope_theta", false]], "rope_theta (jaxgarden.models.llamaconfig attribute)": [[1, "id42", false], [1, "jaxgarden.models.LlamaConfig.rope_theta", false]], "rotary_emb (jaxgarden.models.llamaattention attribute)": [[1, "jaxgarden.models.LlamaAttention.rotary_emb", false]], "rotate_half() (jaxgarden.models.gemma2attention static method)": [[1, "jaxgarden.models.Gemma2Attention.rotate_half", false]], "rotate_half() (jaxgarden.models.llamaattention static method)": [[1, "jaxgarden.models.LlamaAttention.rotate_half", false]], "save() (jaxgarden.models.basemodel method)": [[1, "jaxgarden.models.BaseModel.save", false]], "seed (jaxgarden.models.baseconfig attribute)": [[1, "jaxgarden.models.BaseConfig.seed", false]], "sliding_window (jaxgarden.models.gemma3config attribute)": [[1, "id29", false], [1, "jaxgarden.models.Gemma3Config.sliding_window", false]], "sliding_window_pattern (jaxgarden.models.gemma3config attribute)": [[1, "id30", false], [1, "jaxgarden.models.Gemma3Config.sliding_window_pattern", false]], "sliding_window_size (jaxgarden.models.gemma2config attribute)": [[1, "jaxgarden.models.Gemma2Config.sliding_window_size", false]], "state (jaxgarden.models.basemodel property)": [[1, "jaxgarden.models.BaseModel.state", false]], "state_dict (jaxgarden.models.basemodel property)": [[1, "jaxgarden.models.BaseModel.state_dict", false]], "tie_word_embeddings (jaxgarden.models.gemma2config attribute)": [[1, "jaxgarden.models.Gemma2Config.tie_word_embeddings", false]], "tie_word_embeddings (jaxgarden.models.gemma3config attribute)": [[1, "id31", false], [1, "jaxgarden.models.Gemma3Config.tie_word_embeddings", false]], "to_dict() (jaxgarden.models.baseconfig method)": [[1, "jaxgarden.models.BaseConfig.to_dict", false]], "token_embed (jaxgarden.models.llamaforcausallm attribute)": [[1, "jaxgarden.models.LlamaForCausalLM.token_embed", false]], "up_proj (jaxgarden.models.llamamlp attribute)": [[1, "jaxgarden.models.LlamaMLP.up_proj", false]], "update() (jaxgarden.models.baseconfig method)": [[1, "jaxgarden.models.BaseConfig.update", false]], "use_cache (jaxgarden.models.gemma3config attribute)": [[1, "id32", false], [1, "jaxgarden.models.Gemma3Config.use_cache", false]], "v_proj (jaxgarden.models.llamaattention attribute)": [[1, "jaxgarden.models.LlamaAttention.v_proj", false]], "vocab_size (jaxgarden.models.gemma2config attribute)": [[1, "jaxgarden.models.Gemma2Config.vocab_size", false]], "vocab_size (jaxgarden.models.gemma3config attribute)": [[1, "id33", false], [1, "jaxgarden.models.Gemma3Config.vocab_size", false]], "vocab_size (jaxgarden.models.llamaconfig attribute)": [[1, "id43", false], [1, "jaxgarden.models.LlamaConfig.vocab_size", false]]}, "objects": {"jaxgarden": [[1, 0, 0, "-", "attention"], [1, 0, 0, "-", "functional"], [1, 0, 0, "-", "models"]], "jaxgarden.attention": [[1, 1, 1, "", "MultiHeadAttention"]], "jaxgarden.attention.MultiHeadAttention": [[1, 2, 1, "", "__init__"]], "jaxgarden.functional": [[1, 3, 1, "", "dot_product_attention"]], "jaxgarden.models": [[1, 1, 1, "", "BaseConfig"], [1, 1, 1, "", "BaseModel"], [1, 1, 1, "", "Gemma2Attention"], [1, 1, 1, "", "Gemma2Config"], [1, 1, 1, "", "Gemma2ForCausalLM"], [1, 1, 1, "", "Gemma2MLP"], [1, 1, 1, "", "Gemma2RMSNorm"], [1, 1, 1, "", "Gemma2RotaryEmbedding"], [1, 1, 1, "", "Gemma3Attention"], [1, 1, 1, "", "Gemma3Config"], [1, 1, 1, "", "Gemma3ForCausalLM"], [1, 1, 1, "", "Gemma3MLP"], [1, 1, 1, "", "Gemma3RMSNorm"], [1, 1, 1, "", "Gemma3RotaryEmbedding"], [1, 1, 1, "", "GenerationMixin"], [1, 1, 1, "", "LlamaAttention"], [1, 1, 1, "", "LlamaConfig"], [1, 1, 1, "", "LlamaForCausalLM"], [1, 1, 1, "", "LlamaMLP"], [1, 1, 1, "", "LlamaRMSNorm"], [1, 1, 1, "", "LlamaRotaryEmbedding"], [1, 1, 1, "", "LlamaTransformerBlock"], [1, 1, 1, "", "ModernBERTEncoder"], [1, 1, 1, "", "ModernBERTForMaskedLM"], [1, 1, 1, "", "ModernBertAttention"], [1, 1, 1, "", "ModernBertEmbeddings"], [1, 1, 1, "", "ModernBertLayer"], [1, 1, 1, "", "ModernBertMLP"]], "jaxgarden.models.BaseConfig": [[1, 4, 1, "", "extra"], [1, 4, 1, "", "log_level"], [1, 4, 1, "", "seed"], [1, 2, 1, "", "to_dict"], [1, 2, 1, "", "update"]], "jaxgarden.models.BaseModel": [[1, 2, 1, "", "__init__"], [1, 2, 1, "", "convert_weights_from_hf"], [1, 2, 1, "", "download_from_hf"], [1, 2, 1, "", "from_hf"], [1, 2, 1, "", "iter_safetensors"], [1, 2, 1, "", "load"], [1, 2, 1, "", "save"], [1, 5, 1, "", "state"], [1, 5, 1, "", "state_dict"]], "jaxgarden.models.Gemma2Attention": [[1, 2, 1, "", "apply_soft_cap"], [1, 2, 1, "", "rotate_half"]], "jaxgarden.models.Gemma2Config": [[1, 4, 1, "", "attn_logits_soft_cap"], [1, 4, 1, "", "context_length"], [1, 4, 1, "", "dtype"], [1, 4, 1, "", "eos_token_id"], [1, 4, 1, "", "final_logit_soft_cap"], [1, 4, 1, "", "head_dim"], [1, 4, 1, "", "hidden_size"], [1, 4, 1, "", "intermediate_size"], [1, 4, 1, "", "num_attention_heads"], [1, 4, 1, "", "num_hidden_layers"], [1, 4, 1, "", "num_key_value_heads"], [1, 4, 1, "", "pad_token_id"], [1, 4, 1, "", "param_dtype"], [1, 4, 1, "", "rms_norm_eps"], [1, 4, 1, "", "rope_theta"], [1, 4, 1, "", "sliding_window_size"], [1, 4, 1, "", "tie_word_embeddings"], [1, 4, 1, "", "vocab_size"]], "jaxgarden.models.Gemma2ForCausalLM": [[1, 4, 1, "", "config"]], "jaxgarden.models.Gemma2MLP": [[1, 2, 1, "", "geglu"]], "jaxgarden.models.Gemma2RotaryEmbedding": [[1, 2, 1, "", "__call__"]], "jaxgarden.models.Gemma3Attention": [[1, 2, 1, "", "apply_soft_cap"]], "jaxgarden.models.Gemma3Config": [[1, 4, 1, "id0", "attention_bias"], [1, 4, 1, "id9", "attention_dropout"], [1, 4, 1, "id10", "attn_logit_soft_cap"], [1, 4, 1, "id11", "bos_token_id"], [1, 4, 1, "", "dtype"], [1, 4, 1, "id12", "eos_token_id"], [1, 4, 1, "id13", "final_logit_soft_cap"], [1, 4, 1, "id14", "head_dim"], [1, 4, 1, "id15", "hidden_activation"], [1, 4, 1, "id16", "hidden_size"], [1, 4, 1, "id17", "initializer_range"], [1, 4, 1, "id18", "intermediate_size"], [1, 4, 1, "id19", "max_position_embeddings"], [1, 4, 1, "id20", "num_attention_heads"], [1, 4, 1, "id21", "num_hidden_layers"], [1, 4, 1, "id22", "num_key_value_heads"], [1, 4, 1, "id23", "pad_token_id"], [1, 4, 1, "", "param_dtype"], [1, 4, 1, "id24", "query_pre_attn_scalar"], [1, 4, 1, "id25", "rms_norm_eps"], [1, 4, 1, "id26", "rope_local_base_freq"], [1, 4, 1, "id27", "rope_scaling"], [1, 4, 1, "id28", "rope_theta"], [1, 4, 1, "id29", "sliding_window"], [1, 4, 1, "id30", "sliding_window_pattern"], [1, 4, 1, "id31", "tie_word_embeddings"], [1, 4, 1, "id32", "use_cache"], [1, 4, 1, "id33", "vocab_size"]], "jaxgarden.models.Gemma3ForCausalLM": [[1, 4, 1, "", "config"]], "jaxgarden.models.Gemma3RotaryEmbedding": [[1, 2, 1, "", "__call__"]], "jaxgarden.models.GenerationMixin": [[1, 2, 1, "", "generate"]], "jaxgarden.models.LlamaAttention": [[1, 2, 1, "", "__call__"], [1, 2, 1, "", "__init__"], [1, 2, 1, "", "apply_rotary_pos_emb"], [1, 4, 1, "", "head_dim"], [1, 4, 1, "", "k_proj"], [1, 4, 1, "", "n_heads"], [1, 4, 1, "", "n_kv_heads"], [1, 4, 1, "", "o_proj"], [1, 4, 1, "", "q_proj"], [1, 2, 1, "", "repeat_kv"], [1, 4, 1, "", "rotary_emb"], [1, 2, 1, "", "rotate_half"], [1, 4, 1, "", "v_proj"]], "jaxgarden.models.LlamaConfig": [[1, 4, 1, "id34", "dim"], [1, 4, 1, "id35", "head_dim"], [1, 4, 1, "id36", "intermediate_size"], [1, 4, 1, "id37", "multiple_of"], [1, 4, 1, "id38", "n_heads"], [1, 4, 1, "id39", "n_kv_heads"], [1, 4, 1, "id40", "n_layers"], [1, 4, 1, "id41", "norm_eps"], [1, 4, 1, "id42", "rope_theta"], [1, 4, 1, "id43", "vocab_size"]], "jaxgarden.models.LlamaForCausalLM": [[1, 2, 1, "", "__call__"], [1, 2, 1, "", "__init__"], [1, 2, 1, "", "convert_weights_from_hf"], [1, 4, 1, "", "layers"], [1, 4, 1, "", "lm_head"], [1, 4, 1, "", "norm"], [1, 4, 1, "", "token_embed"]], "jaxgarden.models.LlamaMLP": [[1, 2, 1, "", "__call__"], [1, 2, 1, "", "__init__"], [1, 4, 1, "", "down_proj"], [1, 4, 1, "", "gate_proj"], [1, 4, 1, "", "up_proj"]], "jaxgarden.models.LlamaRMSNorm": [[1, 2, 1, "", "__call__"], [1, 2, 1, "", "__init__"], [1, 4, 1, "", "norm_eps"], [1, 4, 1, "", "norm_weights"]], "jaxgarden.models.LlamaRotaryEmbedding": [[1, 2, 1, "", "__call__"], [1, 2, 1, "", "__init__"], [1, 4, 1, "", "base"], [1, 4, 1, "", "dim"]], "jaxgarden.models.LlamaTransformerBlock": [[1, 2, 1, "", "__call__"], [1, 2, 1, "", "__init__"], [1, 4, 1, "", "attention"], [1, 4, 1, "", "input_layernorm"], [1, 4, 1, "", "mlp"], [1, 4, 1, "", "post_attention_layernorm"]], "jaxgarden.models.ModernBERTEncoder": [[1, 2, 1, "", "__call__"], [1, 2, 1, "", "__init__"]], "jaxgarden.models.ModernBERTForMaskedLM": [[1, 2, 1, "", "__call__"], [1, 2, 1, "", "__init__"]], "jaxgarden.models.ModernBertAttention": [[1, 2, 1, "", "__call__"], [1, 2, 1, "", "__init__"]], "jaxgarden.models.ModernBertEmbeddings": [[1, 2, 1, "", "__call__"], [1, 2, 1, "", "__init__"]], "jaxgarden.models.ModernBertLayer": [[1, 2, 1, "", "__call__"], [1, 2, 1, "", "__init__"]], "jaxgarden.models.ModernBertMLP": [[1, 2, 1, "", "__call__"], [1, 2, 1, "", "__init__"]]}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "function", "Python function"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "property", "Python property"]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:function", "4": "py:attribute", "5": "py:property"}, "terms": {"": 1, "0": 1, "02": 1, "05": 1, "06": 1, "07467": 1, "09864": 1, "1": 1, "10000": 1, "1000000": 1, "12": 1, "128": 1, "128256": 1, "131072": 1, "14336": 1, "16": 1, "16384": 1, "18": 1, "1910": 1, "1e": 1, "2": 1, "20": 1, "2048": 1, "2104": 1, "2304": 1, "256": 1, "256000": 1, "26": 1, "262208": 1, "2b": 1, "3": 1, "30": 1, "32": 1, "4": 1, "4096": 1, "42": 1, "50": 1, "500000": 1, "512": 1, "6": 1, "64": 1, "8": 1, "8192": 1, "9216": 1, "A": [0, 1], "For": 0, "If": 1, "It": 1, "The": 1, "Then": 0, "__call__": 1, "__init__": 1, "_src": 1, "ab": 1, "abc": 1, "account": 0, "activ": 1, "add": 1, "addit": 1, "after": 1, "ai": 1, "alia": 1, "all": 1, "allow": 1, "along": 1, "alreadi": 1, "also": 1, "altern": 1, "an": 1, "ani": 1, "anoth": 1, "answer": 1, "api": 0, "appli": 1, "apply_rotary_pos_emb": 1, "apply_soft_cap": 1, "ar": 1, "architectur": 1, "arg": 1, "around": 1, "arrai": 1, "arxiv": 1, "attent": 0, "attention_bia": 1, "attention_dropout": 1, "attention_fn": 1, "attention_mask": 1, "attn": 1, "attn_logit_soft_cap": 1, "attn_logits_soft_cap": 1, "auth": 1, "authent": 1, "automat": 1, "autoregress": 1, "avail": 1, "b": 1, "b_size": 1, "backend": 0, "base": 1, "baseconfig": 1, "basemodel": 1, "batch": 1, "batch_siz": 1, "beam": 1, "befor": 1, "begin": 1, "below": 1, "bert": 1, "best": 1, "better": 1, "bfloat16": 1, "bia": 1, "bias_init": 1, "bidirect": 1, "blob": 1, "block": 1, "bool": 1, "boolean": 1, "bos_token_id": 1, "both": 1, "broadcast": 1, "broadcast_dropout": 1, "cach": 1, "calcul": 1, "callabl": 1, "can": 1, "cap": 1, "capabl": 1, "causal": 1, "causallm": 1, "cd": 0, "checkpoint": 1, "class": 1, "clone": 0, "co": 1, "collect": 1, "com": [0, 1], "compat": [0, 1], "compil": 1, "compon": 1, "comput": 1, "config": 1, "configur": 1, "connect": 1, "consid": 1, "consist": 1, "constant": 1, "contain": 1, "context": 1, "context_length": 1, "convers": 1, "convert": 1, "convert_weights_from_hf": 1, "cosin": 1, "creat": 1, "cudnn": 1, "cumul": 1, "data": 1, "decod": 1, "deepmind": 1, "default": 1, "dens": 1, "deriv": 1, "describ": 1, "determin": 1, "determinist": 1, "dev": 0, "develop": 0, "deviat": 1, "dict": 1, "dictionari": 1, "differ": [0, 1], "dim": 1, "dimens": 1, "directori": 1, "do_sampl": 1, "dot": 1, "dot_gener": 1, "dot_product_attent": 1, "down": 1, "down_proj": 1, "download": 1, "download_from_hf": 1, "downstream": 1, "dropout": 1, "dropout_r": 1, "dropout_rng": 1, "dtype": 1, "dure": 1, "e": 0, "each": 1, "effici": 1, "embed": 1, "embedding_dropout": 1, "encod": 1, "end": 1, "ensur": 1, "eos_token_id": 1, "epsilon": 1, "etc": 1, "even": 1, "ever": 1, "everi": 1, "exampl": 1, "exce": 1, "exist": 1, "extend": 1, "extra": 1, "face": 1, "factor": 1, "factori": 1, "fals": 1, "fast": 1, "faster": 1, "featur": 1, "fewer": 1, "file": 1, "filter": 1, "final": 1, "final_logit_soft_cap": 1, "finetun": 1, "first": [0, 1], "flash": 1, "flashattent": 0, "flax": [0, 1], "float": 1, "float32": 1, "folder": 1, "follow": 1, "force_download": 1, "fork": 0, "format": 1, "forward": 1, "frequenc": 1, "from": 1, "from_hf": 1, "full": 1, "function": 0, "gate": 1, "gate_proj": 1, "gde": 0, "geglu": 1, "gelu_pytorch_tanh": 1, "gemma": 1, "gemma2attent": 1, "gemma2config": 1, "gemma2forcausallm": 1, "gemma2mlp": 1, "gemma2rmsnorm": 1, "gemma2rotaryembed": 1, "gemma3": 1, "gemma3attent": 1, "gemma3config": 1, "gemma3forcausallm": 1, "gemma3mlp": 1, "gemma3rmsnorm": 1, "gemma3rotaryembed": 1, "gener": 1, "generationmixin": 1, "git": 0, "github": [0, 1], "global": 1, "global_attn_every_n_lay": 1, "global_rope_theta": 1, "googl": 1, "gqa": 1, "graph": 1, "greedi": 1, "group": 1, "h": 1, "hackabl": 0, "half": 1, "head": 1, "head_dim": 1, "helper": 1, "hf": 1, "hidden": 1, "hidden_activ": 1, "hidden_dim": 1, "hidden_dropout": 1, "hidden_s": 1, "hidden_st": 1, "high": 0, "http": [0, 1], "hub": 1, "hug": 1, "huggingfac": 1, "hyperparamet": 1, "i": 1, "id": 1, "ident": 1, "implement": [0, 1], "import": 1, "improv": 1, "in_featur": 1, "includ": 1, "index": [0, 1], "indic": 1, "infer": 1, "info": 1, "init": 1, "initi": 1, "initializer_rang": 1, "input": 1, "input_id": 1, "input_layernorm": 1, "inputs_emb": 1, "instanc": 1, "instead": 1, "int": 1, "integ": 1, "interfac": 0, "intermedi": 1, "intermediate_s": 1, "iter": 1, "iter_safetensor": 1, "jax": [0, 1], "jax_lay": 1, "jaxgarden": 1, "jit": 1, "jnp": 1, "k": 1, "k_proj": 1, "kei": 1, "kernal": 0, "kernel": 1, "kernel_init": 1, "kv": 1, "kv_len": 1, "kv_length": 1, "kwarg": 1, "l": 1, "l41": 1, "languag": 1, "last": 1, "lax": 1, "layer": [0, 1], "layer_id": 1, "layer_idx": 1, "layernorm": 1, "lazili": 1, "learn": 1, "left": 1, "length": 1, "leverag": 0, "librari": 1, "like": [0, 1], "linear": 1, "list": 1, "liter": 1, "llama": 1, "llamaattent": 1, "llamaconfig": 1, "llamaforcausallm": 1, "llamamlp": 1, "llamarmsnorm": 1, "llamarotaryembed": 1, "llamatransformerblock": 1, "lm_head": 1, "load": 1, "local": 1, "local_attent": 1, "local_dir": 1, "local_rope_theta": 1, "log_level": 1, "logit": 1, "long": 1, "longer": 1, "machin": 0, "main": 1, "manag": 1, "mask": 1, "match": 1, "matrix": 1, "max": 1, "max_length": 1, "max_position_embed": 1, "maximum": 1, "mean": 1, "mechan": 1, "memori": 1, "method": 1, "might": 1, "min": 1, "min_p": 1, "mix": 1, "mixin": 1, "ml": 0, "mlp": 1, "mlp_bia": 1, "mlp_dropout": 1, "model": 0, "model_repo_or_id": 1, "modern": 1, "modernbert": 1, "modernbertattent": 1, "modernbertconfig": 1, "modernbertembed": 1, "modernbertencod": 1, "modernbertformaskedlm": 1, "modernbertlay": 1, "modernbertmlp": 1, "modul": 0, "multi": 1, "multiheadattent": [0, 1], "multipl": 1, "multiple_of": 1, "must": 1, "n": 1, "n_head": 1, "n_kv_head": 1, "n_layer": 1, "n_repeat": 1, "name": 1, "need": 1, "network": 0, "neural": 0, "new": 1, "next": 1, "nnx": [0, 1], "none": 1, "norm": 1, "norm_bia": 1, "norm_ep": 1, "norm_weight": 1, "normal": 1, "normalize_qk": 1, "num_attention_head": 1, "num_head": 1, "num_hidden_lay": 1, "num_key_value_head": 1, "number": 1, "numer": 1, "numpi": 1, "o_proj": 1, "object": 1, "ones": 1, "onli": 1, "optim": 0, "option": 1, "orbax": 1, "org": 1, "origin": 1, "other": 1, "otherwis": 1, "out_bias_init": 1, "out_dot_gener": 1, "out_dot_general_cl": 1, "out_featur": 1, "out_kernel_init": 1, "output": 1, "output_attent": 1, "output_hidden_st": 1, "over": 1, "p": 1, "pad": 1, "pad_token_id": 1, "page": 0, "paper": 1, "param": 1, "param_dtyp": 1, "paramet": 1, "pass": 1, "path": 1, "path_to_model_weight": 1, "pattern": 1, "perform": [0, 1], "period": 1, "pip": 0, "pointwis": 1, "posit": 1, "position_id": 1, "post_attention_layernorm": 1, "pre": 1, "precis": 1, "predict": 1, "prepar": 1, "prng": 1, "prngkei": 1, "prob": 1, "probabl": 1, "product": 1, "project": 1, "properti": 1, "provid": [0, 1], "py": 1, "python": 1, "q": 1, "q_len": 1, "q_length": 1, "q_proj": 1, "qk": 1, "qk_depth_per_head": 1, "qkv": 1, "qkv_dot_gener": 1, "qkv_dot_general_cl": 1, "qkv_featur": 1, "qkvo": 1, "queri": 1, "query_pre_attn_scalar": 1, "random": 1, "randomli": 1, "rate": 1, "read": 1, "remov": 1, "remove_hf_after_convers": 1, "repeat": 1, "repeat_kv": 1, "replac": 1, "repo_id": 1, "report": 1, "repositori": [0, 1], "requir": 1, "residu": 1, "return": 1, "right": 1, "rm": 1, "rms_norm_ep": 1, "rmsnorm": 1, "rng": 1, "rnglib": 1, "root": 1, "rope": 1, "rope_local_base_freq": 1, "rope_sc": 1, "rope_theta": 1, "rotari": 1, "rotary_emb": 1, "rotat": 1, "rotate_half": 1, "rotated_k": 1, "rotated_q": 1, "safetensor": 1, "same": 1, "sampl": 1, "save": 1, "save_in_orbax": 1, "scale": 1, "score": 1, "search": [0, 1], "seed": 1, "select": 1, "self": 1, "seq_len": 1, "seq_length": 1, "sequenc": 1, "serial": 1, "set": 1, "shape": 1, "share": 1, "should": 1, "signal": 1, "silu": 1, "similar": 1, "sin": 1, "sinc": 1, "sine": 1, "singl": 1, "sinusoid": 1, "size": 1, "slide": 1, "sliding_window": 1, "sliding_window_mask": 1, "sliding_window_pattern": 1, "sliding_window_s": 1, "small": 1, "smallest": 1, "smarter": 1, "soft": 1, "softmax": 1, "sourc": 1, "sow": 1, "specifi": 1, "split": 1, "squar": 1, "stabil": 1, "standard": 1, "state": 1, "state_dict": 1, "static": 1, "store": 1, "str": 1, "string": 1, "subclass": 1, "support": [0, 1], "swiglu": 1, "task": 1, "technic": 1, "temperatur": 1, "tensor": 1, "text": 1, "than": 1, "thi": 1, "through": 1, "tie": 1, "tie_word_embed": 1, "time": 1, "to_dict": 1, "token": 1, "token_emb": 1, "top": 1, "top_k": 1, "top_p": 1, "tradit": 1, "transform": 1, "tril": 1, "true": 1, "tupl": 1, "type": 1, "unit": 1, "unsqueez": 1, "unsqueeze_dim": 1, "up": 1, "up_proj": 1, "updat": 1, "us": 1, "usag": 1, "use_bia": 1, "use_cach": 1, "use_jit": 1, "v_depth_per_head": 1, "v_proj": 1, "valu": 1, "varianc": 1, "variance_sc": 1, "variant": 1, "variou": 1, "vocab_s": 1, "vocabulari": 1, "we": 1, "weight": 1, "when": 1, "whether": 1, "which": 1, "while": 1, "whose": 1, "window": 1, "without": 1, "wrapper": 1, "x": 1, "xla": 1, "your": 0, "yourusernam": 0, "zero": 1}, "titles": ["Welcome to JAXgarden documentation!", "API Documentation"], "titleterms": {"api": 1, "attent": 1, "content": 0, "document": [0, 1], "featur": 0, "function": 1, "indic": 0, "instal": 0, "interfac": 1, "jaxgarden": 0, "model": 1, "modul": 1, "tabl": 0, "welcom": 0}})